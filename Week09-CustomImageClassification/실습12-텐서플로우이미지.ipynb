{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 2.x 내 이미지 분류\n",
    "\n",
    "## 빅데이터\n",
    "\n",
    "### 이영석, 문현수\n",
    "\n",
    "#### munhyunsu@cs-cnu.org\n",
    "\n",
    "#### 참고자료\n",
    "- [파이썬 3 표준 문서](https://docs.python.org/3/index.html)\n",
    "- [텐서플로우 이미지 분류](https://www.tensorflow.org/tutorials/keras/classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 도구 불러오기 및 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 준비\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf # 텐서플로우\n",
    "import matplotlib.pyplot as plt # 시각화 도구\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tensorflow 버전을 확인합니다: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional. 학습데이터 처리\n",
    "- CIFAR 10 이미지를 위해서는 불필요함.\n",
    "- 자신의 데이터를 이용해서 분류하는 방법을 익히기 위하여 처리.\n",
    "- Python3 dict to jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_root = 'cifar-10-batches-py'\n",
    "# png_root = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unpickle(file):\n",
    "#     with open(file, 'rb') as fo:\n",
    "#         data = pickle.load(fo, encoding='bytes')\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = unpickle(os.path.join(pickle_root, 'batches.meta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_names = []\n",
    "# for label in meta[b'label_names']:\n",
    "#     label_names.append(label.decode('utf-8'))\n",
    "# label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bpath in ['data_batch_1', 'data_batch_2', 'data_batch_3',\n",
    "#               'data_batch_4', 'data_batch_5', 'test_batch']:\n",
    "#     data = unpickle(os.path.join(pickle_root, bpath))\n",
    "#     for raw, label, filename in zip(data[b'data'], data[b'labels'], data[b'filenames']):\n",
    "#         raw = raw.reshape(32, 32, 3, order='F').swapaxes(0, 1)\n",
    "#         label_name = label_names[label]\n",
    "#         odir = os.path.join(png_root, label_name)\n",
    "#         os.makedirs(odir, exist_ok=True)\n",
    "#         opath = os.path.join(png_root, label_name, filename.decode('utf-8'))\n",
    "#         image = Image.fromarray(raw)\n",
    "#         image.save(opath)\n",
    "#     print(f'Done {bpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "png_root = 'dataset'\n",
    "dataset_root = os.path.abspath(os.path.expanduser(png_root))\n",
    "print(f'Dataset root: {dataset_root}')\n",
    "\n",
    "IMAGE_SHAPE = (32, 32)\n",
    "BATCH_SIZE = 1000\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n",
    "                                                                  validation_split=0.2)\n",
    "train_data = image_generator.flow_from_directory(dataset_root, target_size=IMAGE_SHAPE,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 subset='training')\n",
    "validation_data = image_generator.flow_from_directory(dataset_root, target_size=IMAGE_SHAPE,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      subset='validation')\n",
    "label_names = sorted(validation_data.class_indices.items(), key=lambda pair:pair[1])\n",
    "label_names = np.array([key.title() for key, value in label_names])\n",
    "\n",
    "for image_batch, label_batch in validation_data:\n",
    "    print(f'Image batch shape: {image_batch.shape}')\n",
    "    print(f'Label batch shape: {label_batch.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 학습 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0\n",
    "N = 30\n",
    "\n",
    "fig = plt.figure(figsize=(12, 2.75*(N//5)))\n",
    "fig.suptitle('Example of train image', fontsize=24)\n",
    "for n in range(IDX, IDX+N):\n",
    "    ax = fig.add_subplot(N//5, 5, n+1)\n",
    "    ax.imshow(image_batch[n])\n",
    "    ax.set_title(f'{n}-{label_names[np.argmax(label_batch[n])]}', fontsize=16)\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=image_batch.shape[1:]),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(train_data.num_classes)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_data,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get result labels\n",
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = label_names[predicted_id]\n",
    "\n",
    "label_id = np.argmax(label_batch, axis=-1)\n",
    "\n",
    "## plot\n",
    "fig = plt.figure(figsize=(10, 10.5))\n",
    "for n in range(30):\n",
    "    ax = fig.add_subplot(6, 5, n+1)\n",
    "    ax.imshow(image_batch[n])\n",
    "    color = 'green' if predicted_id[n] == label_id[n] else 'red'\n",
    "    ax.set_title(predicted_label_batch[n].title(), color=color)\n",
    "    ax.axis('off')\n",
    "_ = fig.suptitle('Model predictions (green: correct, red: incorrect)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
